{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T08:26:19.047916Z",
     "start_time": "2025-04-04T08:26:19.045314Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix, cohen_kappa_score, roc_curve, roc_auc_score, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.metrics import AUC\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "import time\n",
    "import numpy as np\n",
    "import ember\n",
    "import lightgbm as lgb\n",
    "import warnings"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Loading the Data**",
   "id": "47072c4861e32d4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:19.859158Z",
     "start_time": "2025-04-04T09:41:19.754348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#UPDATE THIS PATH\n",
    "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"/Users/alexandrutodea/Downloads/ember2018_data\")"
   ],
   "id": "1d9aa48fc3833956",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
      "WARNING:   lief version 0.16.4-10f74acf found instead. There may be slight inconsistencies\n",
      "WARNING:   in the feature calculations.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dataset Contents:\n",
    "\n",
    "- Training Data: 300,000 malicious samples / 300,000 benign samples / 200,000 unlabeled samples (not taken into account)\n",
    "- Testing Data: 100,000 malicious samples / 100,000 benign samples\n",
    "\n",
    "The feature groups in the dataset:\n",
    "\n",
    "- 0 to 255: Byte Histogram\n",
    "- 256 to 511: Byte-entropy Histogram\n",
    "- 512 to 615: String Information\n",
    "- 616 to 625: General File Information\n",
    "- 626 to 687: Header Information\n",
    "- 688 to 942: Section Information\n",
    "- 943 to 2222: Imported Functions\n",
    "- 2223 to 2350: Exported Functions\n",
    "- 2351 to 2380: Data Directories"
   ],
   "id": "cf615d0bec43e926"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Finds the positions of all benign samples in the training set**",
   "id": "3556a59cd30da15a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:22.737394Z",
     "start_time": "2025-04-04T09:41:22.729038Z"
    }
   },
   "cell_type": "code",
   "source": "ben=np.where(y_train==0)",
   "id": "9923104758c4a56e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Finds the positions of all malicious samples in the training set**",
   "id": "f237ede80e21dbfc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:24.314083Z",
     "start_time": "2025-04-04T09:41:24.311310Z"
    }
   },
   "cell_type": "code",
   "source": "mal=np.where(y_train==1)",
   "id": "74417a066bc586e1",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Combines all training indices (both benign and malicious)**",
   "id": "5ddcbc351b1359d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:26.089062Z",
     "start_time": "2025-04-04T09:41:26.086661Z"
    }
   },
   "cell_type": "code",
   "source": "n = np.concatenate((ben, mal), axis=1).reshape(600000)",
   "id": "f8b724a9cf94e3ea",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Random seed set by the authors of https://ieeexplore.ieee.org/abstract/document/10460035**",
   "id": "44d3e5ed81e75f84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:27.793075Z",
     "start_time": "2025-04-04T09:41:27.791373Z"
    }
   },
   "cell_type": "code",
   "source": "np.random.seed(314)",
   "id": "7118dc6e8dfde5f8",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Randomly shuffles the indices in n**",
   "id": "da2740ad59901aa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:29.647768Z",
     "start_time": "2025-04-04T09:41:29.639973Z"
    }
   },
   "cell_type": "code",
   "source": "np.random.shuffle(n)",
   "id": "44eef01d13fec24f",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Picks benign and malicious samples from y_train in the shuffled order**",
   "id": "1eb823f585e6ca6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:31.463456Z",
     "start_time": "2025-04-04T09:41:31.461004Z"
    }
   },
   "cell_type": "code",
   "source": "y_train = y_train[n]",
   "id": "85febb9905bcb1cb",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Picks benign and malicious samples from X_train in the shuffled order**",
   "id": "fa29746b335796c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:37.966583Z",
     "start_time": "2025-04-04T09:41:33.246224Z"
    }
   },
   "cell_type": "code",
   "source": "X_train = X_train[n]",
   "id": "dbc4b31e6ba980a8",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Checks the Sizes to Ensure Everything is OK**",
   "id": "d7fe54d1b44c5fff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:40.375647Z",
     "start_time": "2025-04-04T09:41:40.373323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_rows, X_train_columns = X_train.shape\n",
    "X_test_rows, X_test_columns = X_test.shape\n",
    "y_train_shape = y_train.shape\n",
    "y_test_shape = y_test.shape\n",
    "print(\"Number of rows in X_train: \", X_train_rows)\n",
    "print(\"Number of columns in X_train: \", X_train_columns)\n",
    "print(\"Number of rows in X_test: \", X_test_rows)\n",
    "print(\"Number of columns in X_test: \", X_test_columns)\n",
    "print(\"y_train Shape (should be 1D): \", y_train_shape)\n",
    "print(\"y_test Shape (should be 1D): \", y_test_shape)"
   ],
   "id": "b0762bcb4b78d6f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in X_train:  600000\n",
      "Number of columns in X_train:  2381\n",
      "Number of rows in X_test:  200000\n",
      "Number of columns in X_test:  2381\n",
      "y_train Shape (should be 1D):  (600000,)\n",
      "y_test Shape (should be 1D):  (200000,)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**PART I:** Replicating Results from https://ieeexplore.ieee.org/abstract/document/10460035 (Code Source: https://github.com/CollinConnors/Machine-learning-for-detecting-malware-in-pe-files)",
   "id": "729fcc0d303f50a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:44.723289Z",
     "start_time": "2025-04-04T09:41:44.717504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)"
   ],
   "id": "eb6c882e472e8462",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Defining the Model**\n",
   "id": "2fef8e79dcf10f42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:41:46.640252Z",
     "start_time": "2025-04-04T09:41:46.618505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "modinput = Input(shape=(X_train.shape[1],), dtype='float32', name='Input')\n",
    "BNOne = BatchNormalization(name='BatchNormalization_Input')(modinput)\n",
    "denseLayerOne = Dense(512, activation='tanh', name='Dense1')(BNOne)\n",
    "denseLayerTwo = Dense(128, activation='tanh', name='Dense2')(denseLayerOne)\n",
    "BNTwo = BatchNormalization(name='BatchNormalization_Dense2')(denseLayerTwo)\n",
    "denseLayerThree = Dense(8, activation='tanh', name='Dense3')(BNTwo)\n",
    "output = Dense(2, activation='softmax', name='Out')(denseLayerThree)\n",
    "\n",
    "DLModel = Model(modinput, output, name='DLModel')\n",
    "DLModel.summary()"
   ],
   "id": "c249fb4545db9126",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"DLModel\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DLModel\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001B[38;5;33mInputLayer\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2381\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BatchNormalization_Input        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2381\u001B[0m)           │         \u001B[38;5;34m9,524\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense1 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │     \u001B[38;5;34m1,219,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │        \u001B[38;5;34m65,664\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BatchNormalization_Dense2       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense3 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)              │         \u001B[38;5;34m1,032\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Out (\u001B[38;5;33mDense\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │            \u001B[38;5;34m18\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2381</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BatchNormalization_Input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2381</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,524</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,219,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BatchNormalization_Dense2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,296,334\u001B[0m (4.95 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,296,334</span> (4.95 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,291,316\u001B[0m (4.93 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,291,316</span> (4.93 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m5,018\u001B[0m (19.60 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,018</span> (19.60 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Training the Model and Saving Its Weights After the Best Epoch**",
   "id": "8b5d40c6e8e30637"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:04:50.570160Z",
     "start_time": "2025-04-04T09:41:54.984432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# UPDATE THIS PATH\n",
    "path = \"./DLModel.weights.h5\"\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path, save_weights_only=True,\n",
    "                                                            monitor='val_acc', mode='max', save_best_only=True)\n",
    "\n",
    "train_start = time.time()\n",
    "DLModel.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=['acc', AUC()])\n",
    "DLModel.fit(X_train, y_train, epochs=75, batch_size=200, verbose=1, validation_data=(X_test, y_test),\n",
    "          callbacks=[model_checkpoint_callback])\n",
    "train_end = time.time()"
   ],
   "id": "2c0cc17d15f3674f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 5ms/step - acc: 0.9119 - auc_5: 0.9708 - loss: 0.2117 - val_acc: 0.9148 - val_auc_5: 0.9745 - val_loss: 0.2066\n",
      "Epoch 2/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 6ms/step - acc: 0.9521 - auc_5: 0.9910 - loss: 0.1198 - val_acc: 0.9319 - val_auc_5: 0.9802 - val_loss: 0.1797\n",
      "Epoch 3/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 6ms/step - acc: 0.9600 - auc_5: 0.9934 - loss: 0.1016 - val_acc: 0.9258 - val_auc_5: 0.9795 - val_loss: 0.1835\n",
      "Epoch 4/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9643 - auc_5: 0.9947 - loss: 0.0905 - val_acc: 0.9341 - val_auc_5: 0.9799 - val_loss: 0.1824\n",
      "Epoch 5/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9666 - auc_5: 0.9954 - loss: 0.0847 - val_acc: 0.9352 - val_auc_5: 0.9797 - val_loss: 0.1842\n",
      "Epoch 6/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9691 - auc_5: 0.9959 - loss: 0.0786 - val_acc: 0.9318 - val_auc_5: 0.9783 - val_loss: 0.1931\n",
      "Epoch 7/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9707 - auc_5: 0.9962 - loss: 0.0754 - val_acc: 0.9394 - val_auc_5: 0.9821 - val_loss: 0.1720\n",
      "Epoch 8/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9721 - auc_5: 0.9966 - loss: 0.0712 - val_acc: 0.9363 - val_auc_5: 0.9801 - val_loss: 0.1837\n",
      "Epoch 9/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9730 - auc_5: 0.9967 - loss: 0.0695 - val_acc: 0.9430 - val_auc_5: 0.9825 - val_loss: 0.1703\n",
      "Epoch 10/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9744 - auc_5: 0.9971 - loss: 0.0659 - val_acc: 0.9424 - val_auc_5: 0.9817 - val_loss: 0.1749\n",
      "Epoch 11/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9747 - auc_5: 0.9972 - loss: 0.0643 - val_acc: 0.9424 - val_auc_5: 0.9819 - val_loss: 0.1735\n",
      "Epoch 12/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9761 - auc_5: 0.9974 - loss: 0.0618 - val_acc: 0.9438 - val_auc_5: 0.9826 - val_loss: 0.1698\n",
      "Epoch 13/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9767 - auc_5: 0.9975 - loss: 0.0602 - val_acc: 0.9419 - val_auc_5: 0.9809 - val_loss: 0.1832\n",
      "Epoch 14/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9772 - auc_5: 0.9976 - loss: 0.0589 - val_acc: 0.9363 - val_auc_5: 0.9785 - val_loss: 0.1943\n",
      "Epoch 15/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9775 - auc_5: 0.9978 - loss: 0.0578 - val_acc: 0.9391 - val_auc_5: 0.9801 - val_loss: 0.1851\n",
      "Epoch 16/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9776 - auc_5: 0.9978 - loss: 0.0569 - val_acc: 0.9448 - val_auc_5: 0.9812 - val_loss: 0.1757\n",
      "Epoch 17/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9781 - auc_5: 0.9978 - loss: 0.0561 - val_acc: 0.9299 - val_auc_5: 0.9765 - val_loss: 0.2162\n",
      "Epoch 18/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9789 - auc_5: 0.9979 - loss: 0.0543 - val_acc: 0.9326 - val_auc_5: 0.9780 - val_loss: 0.2003\n",
      "Epoch 19/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9791 - auc_5: 0.9981 - loss: 0.0528 - val_acc: 0.9324 - val_auc_5: 0.9777 - val_loss: 0.2147\n",
      "Epoch 20/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9795 - auc_5: 0.9981 - loss: 0.0525 - val_acc: 0.9408 - val_auc_5: 0.9789 - val_loss: 0.1933\n",
      "Epoch 21/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9800 - auc_5: 0.9981 - loss: 0.0514 - val_acc: 0.9410 - val_auc_5: 0.9791 - val_loss: 0.1913\n",
      "Epoch 22/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9802 - auc_5: 0.9982 - loss: 0.0510 - val_acc: 0.9451 - val_auc_5: 0.9810 - val_loss: 0.1817\n",
      "Epoch 23/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9804 - auc_5: 0.9982 - loss: 0.0505 - val_acc: 0.9445 - val_auc_5: 0.9807 - val_loss: 0.1818\n",
      "Epoch 24/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9805 - auc_5: 0.9982 - loss: 0.0504 - val_acc: 0.9452 - val_auc_5: 0.9811 - val_loss: 0.1810\n",
      "Epoch 25/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9809 - auc_5: 0.9983 - loss: 0.0488 - val_acc: 0.9454 - val_auc_5: 0.9808 - val_loss: 0.1786\n",
      "Epoch 26/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 6ms/step - acc: 0.9811 - auc_5: 0.9983 - loss: 0.0487 - val_acc: 0.9417 - val_auc_5: 0.9792 - val_loss: 0.1942\n",
      "Epoch 27/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9815 - auc_5: 0.9983 - loss: 0.0481 - val_acc: 0.9470 - val_auc_5: 0.9808 - val_loss: 0.1818\n",
      "Epoch 28/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9816 - auc_5: 0.9984 - loss: 0.0470 - val_acc: 0.9464 - val_auc_5: 0.9797 - val_loss: 0.1887\n",
      "Epoch 29/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9816 - auc_5: 0.9984 - loss: 0.0473 - val_acc: 0.9455 - val_auc_5: 0.9794 - val_loss: 0.1848\n",
      "Epoch 30/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9818 - auc_5: 0.9984 - loss: 0.0473 - val_acc: 0.9439 - val_auc_5: 0.9811 - val_loss: 0.1832\n",
      "Epoch 31/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9821 - auc_5: 0.9984 - loss: 0.0468 - val_acc: 0.9169 - val_auc_5: 0.9724 - val_loss: 0.2503\n",
      "Epoch 32/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9822 - auc_5: 0.9985 - loss: 0.0457 - val_acc: 0.9414 - val_auc_5: 0.9799 - val_loss: 0.1955\n",
      "Epoch 33/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9826 - auc_5: 0.9986 - loss: 0.0449 - val_acc: 0.9436 - val_auc_5: 0.9812 - val_loss: 0.1801\n",
      "Epoch 34/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9829 - auc_5: 0.9986 - loss: 0.0442 - val_acc: 0.9428 - val_auc_5: 0.9804 - val_loss: 0.1896\n",
      "Epoch 35/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9826 - auc_5: 0.9985 - loss: 0.0449 - val_acc: 0.9497 - val_auc_5: 0.9813 - val_loss: 0.1788\n",
      "Epoch 36/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9827 - auc_5: 0.9986 - loss: 0.0444 - val_acc: 0.9430 - val_auc_5: 0.9791 - val_loss: 0.1983\n",
      "Epoch 37/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 7ms/step - acc: 0.9829 - auc_5: 0.9986 - loss: 0.0441 - val_acc: 0.9464 - val_auc_5: 0.9817 - val_loss: 0.1858\n",
      "Epoch 38/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9831 - auc_5: 0.9986 - loss: 0.0435 - val_acc: 0.9505 - val_auc_5: 0.9832 - val_loss: 0.1702\n",
      "Epoch 39/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9834 - auc_5: 0.9986 - loss: 0.0430 - val_acc: 0.9369 - val_auc_5: 0.9773 - val_loss: 0.2093\n",
      "Epoch 40/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9836 - auc_5: 0.9987 - loss: 0.0421 - val_acc: 0.9412 - val_auc_5: 0.9797 - val_loss: 0.1967\n",
      "Epoch 41/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9832 - auc_5: 0.9987 - loss: 0.0431 - val_acc: 0.9384 - val_auc_5: 0.9785 - val_loss: 0.2040\n",
      "Epoch 42/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9832 - auc_5: 0.9986 - loss: 0.0433 - val_acc: 0.9430 - val_auc_5: 0.9793 - val_loss: 0.1894\n",
      "Epoch 43/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9837 - auc_5: 0.9987 - loss: 0.0420 - val_acc: 0.9453 - val_auc_5: 0.9808 - val_loss: 0.1875\n",
      "Epoch 44/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9835 - auc_5: 0.9987 - loss: 0.0422 - val_acc: 0.9474 - val_auc_5: 0.9812 - val_loss: 0.1815\n",
      "Epoch 45/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9835 - auc_5: 0.9987 - loss: 0.0422 - val_acc: 0.9487 - val_auc_5: 0.9812 - val_loss: 0.1847\n",
      "Epoch 46/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9838 - auc_5: 0.9987 - loss: 0.0418 - val_acc: 0.9346 - val_auc_5: 0.9773 - val_loss: 0.2188\n",
      "Epoch 47/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9844 - auc_5: 0.9988 - loss: 0.0403 - val_acc: 0.9410 - val_auc_5: 0.9792 - val_loss: 0.2009\n",
      "Epoch 48/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 6ms/step - acc: 0.9840 - auc_5: 0.9988 - loss: 0.0411 - val_acc: 0.9348 - val_auc_5: 0.9748 - val_loss: 0.2300\n",
      "Epoch 49/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9843 - auc_5: 0.9988 - loss: 0.0403 - val_acc: 0.9332 - val_auc_5: 0.9782 - val_loss: 0.2150\n",
      "Epoch 50/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9845 - auc_5: 0.9988 - loss: 0.0402 - val_acc: 0.9378 - val_auc_5: 0.9767 - val_loss: 0.2138\n",
      "Epoch 51/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9845 - auc_5: 0.9988 - loss: 0.0402 - val_acc: 0.9477 - val_auc_5: 0.9805 - val_loss: 0.1876\n",
      "Epoch 52/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9843 - auc_5: 0.9987 - loss: 0.0408 - val_acc: 0.9362 - val_auc_5: 0.9783 - val_loss: 0.2090\n",
      "Epoch 53/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9847 - auc_5: 0.9988 - loss: 0.0396 - val_acc: 0.9265 - val_auc_5: 0.9662 - val_loss: 0.2717\n",
      "Epoch 54/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9844 - auc_5: 0.9988 - loss: 0.0402 - val_acc: 0.9452 - val_auc_5: 0.9813 - val_loss: 0.1819\n",
      "Epoch 55/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9844 - auc_5: 0.9988 - loss: 0.0401 - val_acc: 0.9375 - val_auc_5: 0.9781 - val_loss: 0.2102\n",
      "Epoch 56/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9844 - auc_5: 0.9988 - loss: 0.0400 - val_acc: 0.9421 - val_auc_5: 0.9797 - val_loss: 0.1945\n",
      "Epoch 57/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9847 - auc_5: 0.9988 - loss: 0.0392 - val_acc: 0.9433 - val_auc_5: 0.9787 - val_loss: 0.2025\n",
      "Epoch 58/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9851 - auc_5: 0.9989 - loss: 0.0388 - val_acc: 0.9424 - val_auc_5: 0.9784 - val_loss: 0.2046\n",
      "Epoch 59/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9848 - auc_5: 0.9988 - loss: 0.0394 - val_acc: 0.9339 - val_auc_5: 0.9789 - val_loss: 0.2078\n",
      "Epoch 60/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9849 - auc_5: 0.9989 - loss: 0.0393 - val_acc: 0.9449 - val_auc_5: 0.9796 - val_loss: 0.2020\n",
      "Epoch 61/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9851 - auc_5: 0.9989 - loss: 0.0383 - val_acc: 0.9407 - val_auc_5: 0.9774 - val_loss: 0.2083\n",
      "Epoch 62/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9852 - auc_5: 0.9989 - loss: 0.0383 - val_acc: 0.9447 - val_auc_5: 0.9796 - val_loss: 0.2004\n",
      "Epoch 63/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9851 - auc_5: 0.9989 - loss: 0.0380 - val_acc: 0.9444 - val_auc_5: 0.9795 - val_loss: 0.1993\n",
      "Epoch 64/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9854 - auc_5: 0.9989 - loss: 0.0378 - val_acc: 0.9389 - val_auc_5: 0.9769 - val_loss: 0.2182\n",
      "Epoch 65/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9852 - auc_5: 0.9989 - loss: 0.0383 - val_acc: 0.9443 - val_auc_5: 0.9770 - val_loss: 0.2051\n",
      "Epoch 66/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9853 - auc_5: 0.9989 - loss: 0.0374 - val_acc: 0.9280 - val_auc_5: 0.9752 - val_loss: 0.2332\n",
      "Epoch 67/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9847 - auc_5: 0.9989 - loss: 0.0389 - val_acc: 0.9418 - val_auc_5: 0.9795 - val_loss: 0.2004\n",
      "Epoch 68/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9855 - auc_5: 0.9989 - loss: 0.0378 - val_acc: 0.9458 - val_auc_5: 0.9800 - val_loss: 0.1939\n",
      "Epoch 69/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9854 - auc_5: 0.9989 - loss: 0.0376 - val_acc: 0.9421 - val_auc_5: 0.9796 - val_loss: 0.2023\n",
      "Epoch 70/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9854 - auc_5: 0.9989 - loss: 0.0377 - val_acc: 0.9483 - val_auc_5: 0.9802 - val_loss: 0.1932\n",
      "Epoch 71/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9855 - auc_5: 0.9989 - loss: 0.0376 - val_acc: 0.9384 - val_auc_5: 0.9762 - val_loss: 0.2187\n",
      "Epoch 72/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9848 - auc_5: 0.9989 - loss: 0.0383 - val_acc: 0.9295 - val_auc_5: 0.9749 - val_loss: 0.2317\n",
      "Epoch 73/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 6ms/step - acc: 0.9856 - auc_5: 0.9990 - loss: 0.0367 - val_acc: 0.9309 - val_auc_5: 0.9745 - val_loss: 0.2430\n",
      "Epoch 74/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9854 - auc_5: 0.9989 - loss: 0.0370 - val_acc: 0.9423 - val_auc_5: 0.9771 - val_loss: 0.2125\n",
      "Epoch 75/75\n",
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 6ms/step - acc: 0.9851 - auc_5: 0.9989 - loss: 0.0378 - val_acc: 0.9401 - val_auc_5: 0.9780 - val_loss: 0.2112\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Evaluating the Model's Performance**\n",
   "id": "9b06255248a95dcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:14:48.513051Z",
     "start_time": "2025-04-04T10:14:36.054873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DLModel.load_weights(path)\n",
    "\n",
    "# Evaluate the model\n",
    "modStats = DLModel.evaluate(X_test, y_test)\n",
    "loss = modStats[0]\n",
    "acc = modStats[1]\n",
    "auc = modStats[2]\n",
    "\n",
    "# Get predictions\n",
    "start_inference = time.time()\n",
    "y_pred_probs = DLModel.predict(X_test)\n",
    "end_inference = time.time()\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Compute metrics\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "# Convert training time to minutes and seconds\n",
    "training_total_seconds = train_end - train_start\n",
    "train_minutes = int(training_total_seconds // 60)\n",
    "train_seconds = training_total_seconds % 60\n",
    "\n",
    "# Convert inference time to minutes and seconds\n",
    "inference_total_seconds = end_inference - start_inference\n",
    "inference_minutes = int(inference_total_seconds // 60)\n",
    "inference_seconds = inference_total_seconds % 60\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"Cohen's Kappa Score: {kappa:.4f}\")\n",
    "#print(f\"Training Time: {training_time_minutes:.2f} minutes\")\n",
    "print(f\"Training Time: {train_minutes} minutes and {train_seconds:.2f} seconds\")\n",
    "print(f\"Inference Time: {inference_minutes} minutes and {inference_seconds:.2f} seconds\")"
   ],
   "id": "e7b7c66716ae525e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6250/6250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 957us/step - acc: 0.9550 - auc_5: 0.9850 - loss: 0.1561\n",
      "\u001B[1m6250/6250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 897us/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95289  4711]\n",
      " [ 5184 94816]]\n",
      "\n",
      "True Negatives (TN): 95289\n",
      "False Positives (FP): 4711\n",
      "False Negatives (FN): 5184\n",
      "True Positives (TP): 94816\n",
      "Test Accuracy: 0.9505\n",
      "Test AUC: 0.9832\n",
      "Test Loss: 0.1702\n",
      "Precision: 0.9505\n",
      "Recall: 0.9505\n",
      "F1-Score: 0.9505\n",
      "Cohen's Kappa Score: 0.9011\n",
      "Training Time: 22 minutes and 55.58 seconds\n",
      "Inference Time: 0 minutes and 6.08 seconds\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**PART II: Applying a Variance Threshold on the Training and Testing Data**",
   "id": "fc13fa90026bfb02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Dropping features with variance < 0.001**. \"No change in the features implies no conditional change on the target from which to learn.\" (Machine Learning for Tabular Data by Mark Ryan and Luca Massaron)\n",
   "id": "c57bbef5aa5bc119"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:13:50.954981Z",
     "start_time": "2025-04-04T12:13:33.286985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vt = VarianceThreshold(threshold=1e-3)\n",
    "X_train_vt = vt.fit_transform(X_train)\n",
    "X_test_vt = vt.transform(X_test)"
   ],
   "id": "11066a42dbbcce24",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Verifying that the columns were dropped**",
   "id": "ebaa00deb700ce1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:13:56.993910Z",
     "start_time": "2025-04-04T12:13:56.991855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train_vt.shape[1])\n",
    "print(X_test_vt.shape[1])"
   ],
   "id": "b3518fa9d062c44e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1658\n",
      "1658\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Placing the Dropped Columns in a List**",
   "id": "f50b290b01a9cee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:14:03.439657Z",
     "start_time": "2025-04-04T12:14:03.437601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_mask = vt.get_support()\n",
    "dropped_columns = np.where(~selected_mask)[0]\n",
    "dropped_columns = dropped_columns.tolist()"
   ],
   "id": "eea532da12cbe028",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Displaying the Number of Columns That were Dropped from Each Feature Group**",
   "id": "289c01d5050ab41e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:14:07.090393Z",
     "start_time": "2025-04-04T12:14:07.086703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the buckets\n",
    "buckets = {\n",
    "    \"Byte Histogram\": (0, 255),\n",
    "    \"Byte-entropy Histogram\": (256, 511),\n",
    "    \"String Information\": (512, 615),\n",
    "    \"General File Information\": (616, 625),\n",
    "    \"Header Information\": (626, 687),\n",
    "    \"Section Information\": (688, 942),\n",
    "    \"Imported Functions\": (943, 2222),\n",
    "    \"Exported Functions\": (2223, 2350),\n",
    "    \"Data Directories\": (2351, 2380)\n",
    "}\n",
    "\n",
    "# Initialize counter for each bucket\n",
    "bucket_counts = {name: 0 for name in buckets}\n",
    "\n",
    "# Classify each dropped column into the corresponding bucket\n",
    "for val in dropped_columns:\n",
    "    found = False\n",
    "    for name, (start, end) in buckets.items():\n",
    "        if start <= val <= end:\n",
    "            bucket_counts[name] += 1\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Value {val} does not fall into any defined range.\")\n",
    "\n",
    "# Display the counts\n",
    "print(\"Dropped Column Counts by Category:\")\n",
    "for name, count in bucket_counts.items():\n",
    "    print(f\"{name}: {count}\")"
   ],
   "id": "83185b47476349bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped Column Counts by Category:\n",
      "Byte Histogram: 254\n",
      "Byte-entropy Histogram: 249\n",
      "String Information: 95\n",
      "General File Information: 0\n",
      "Header Information: 27\n",
      "Section Information: 66\n",
      "Imported Functions: 32\n",
      "Exported Functions: 0\n",
      "Data Directories: 0\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**PART III: Training and Evaluating the Random Forest Model on the Feature-Reduced Dataset**",
   "id": "987075ec90ad5050"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Resetting y_train and y_test**",
   "id": "3c2e581605633071"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:14:18.960115Z",
     "start_time": "2025-04-04T12:14:18.938825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_second, y_train, X_test_second, y_test = ember.read_vectorized_features(\"/Users/alexandrutodea/Downloads/ember2018_data\")\n",
    "y_train = y_train[n]"
   ],
   "id": "bae7ed348f9178f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
      "WARNING:   lief version 0.16.4-10f74acf found instead. There may be slight inconsistencies\n",
      "WARNING:   in the feature calculations.\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Training the Random Forest Model on the Feature-Reduced Training Data**\n",
   "id": "59401316d5ef309b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:29:06.763852Z",
     "start_time": "2025-04-04T12:25:52.928243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rfm_reduced = RandomForestClassifier(n_estimators=100) #max_depth=None, min_samples_split=2\n",
    "rf_train_start = time.time()\n",
    "rfm_reduced.fit(X_train_vt, y_train)\n",
    "rf_train_end = time.time()"
   ],
   "id": "986226ff2f5eb08a",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Evaluating the Random Forest Model on the Feature-Reduced Testing Data**",
   "id": "60cd9c9b19cb5350"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:29:18.987372Z",
     "start_time": "2025-04-04T12:29:11.804957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Measure inference time\n",
    "rf_infer_start = time.time()\n",
    "rfm_reduced_ypred = rfm_reduced.predict(X_test_vt)\n",
    "rf_infer_end = time.time()\n",
    "\n",
    "# Calculate inference time\n",
    "rf_inference_total_seconds = rf_infer_end - rf_infer_start\n",
    "rf_infer_minutes = int(rf_inference_total_seconds // 60)\n",
    "rf_infer_seconds = rf_inference_total_seconds % 60\n",
    "\n",
    "# Calculate training time\n",
    "rf_training_total_seconds = rf_train_end - rf_train_start\n",
    "rf_train_minutes = int(rf_training_total_seconds // 60)\n",
    "rf_train_seconds = rf_training_total_seconds % 60\n",
    "\n",
    "cm = confusion_matrix(y_test, rfm_reduced_ypred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rfm_reduced_ypred):.4f}\")\n",
    "rfmy_pred_proba = np.array(rfm_reduced.predict_proba(X_test_vt))[:, 1]  # Probabilities for the positive class\n",
    "print(f\"AUC: {roc_auc_score(y_test, rfmy_pred_proba):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, rfm_reduced_ypred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, rfm_reduced_ypred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, rfm_reduced_ypred):.4f}\")\n",
    "print(f\"Cohen's Kappa Score: {cohen_kappa_score(y_test, rfm_reduced_ypred):.4f}\")\n",
    "print(f\"Training Time: {rf_train_minutes} minutes and {rf_train_seconds:.2f} seconds\")\n",
    "print(f\"Inference Time: {rf_infer_minutes} minutes and {rf_infer_seconds:.2f} seconds\")"
   ],
   "id": "3347c8ee1a5157e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[97881  2119]\n",
      " [ 4083 95917]]\n",
      "\n",
      "True Negatives (TN): 97881\n",
      "False Positives (FP): 2119\n",
      "False Negatives (FN): 4083\n",
      "True Positives (TP): 95917\n",
      "Accuracy: 0.9690\n",
      "AUC: 0.9949\n",
      "Precision: 0.9784\n",
      "Recall: 0.9592\n",
      "F1-Score: 0.9687\n",
      "Cohen's Kappa Score: 0.9380\n",
      "Training Time: 3 minutes and 13.83 seconds\n",
      "Inference Time: 0 minutes and 3.64 seconds\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Putting the Results into Perspective**",
   "id": "6dbc4095492aeb1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**1,85% increase in accuracy over the DL Model, which translates to 3700 more correctly labeled samples (2592 false positives correctly reclassified as true negatives; 1101 false negatives correctly reclassified as true positives)**",
   "id": "55fe516d30905543"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**This Random Forest model trains 7,1 times faster than the DL Model (3 minutes and 13,83 seconds vs. 22 minutes and 55,58 seconds)**\n",
   "id": "90467f62f67df036"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The inference time for the 200,000 samples is 1,67 times faster than the DL Model (6,08 seconds vs. 3,64 seconds)**",
   "id": "bb609fa7613181be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**PART IV: Training and Evaluating the LightGBM Model on the Feature-Reduced Dataset**",
   "id": "a560edc11ca70f57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Training the LightGBM Model on the Feature-Reduced Training Data**",
   "id": "2e9b0f5a208ecec8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:45:50.023700Z",
     "start_time": "2025-04-05T14:45:43.692543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lgbm_reduced = lgb.LGBMClassifier() #boosting_type='gbdt; num_leaves=31: (Maximum number of leaves in one tree); max_depth=-1: (No limit on tree depth); learning_rate=0.1; n_estimators=100\n",
    "lgb_train_start = time.time()\n",
    "lgbm_reduced.fit(X_train_vt, y_train)\n",
    "lgb_train_end = time.time()"
   ],
   "id": "e88ba1ffffbfb312",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 300000, number of negative: 300000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.406354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60340\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 1658\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Evaluating the LightGBM Model on the Feature-Reduced Testing Data**",
   "id": "fd44b971d8c60929"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:46:06.097786Z",
     "start_time": "2025-04-05T14:46:05.585368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lgb_training_total_seconds = lgb_train_end - lgb_train_start\n",
    "lgb_train_minutes = int(lgb_training_total_seconds // 60)\n",
    "lgb_train_seconds = lgb_training_total_seconds % 60\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    lgb_infer_start = time.time()\n",
    "    lgb_reduced_ypred = lgbm_reduced.predict(X_test_vt)\n",
    "    lgb_infer_end = time.time()\n",
    "    lgby_pred_proba = np.array(lgbm_reduced.predict_proba(X_test_vt))[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "lgb_infer_total_seconds = lgb_infer_end - lgb_infer_start\n",
    "lgb_infer_minutes = int(lgb_infer_total_seconds // 60)\n",
    "lgb_infer_seconds = lgb_infer_total_seconds % 60\n",
    "\n",
    "cm = confusion_matrix(y_test, lgb_reduced_ypred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lgb_reduced_ypred):.4f}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, lgby_pred_proba):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, lgb_reduced_ypred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, lgb_reduced_ypred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, lgb_reduced_ypred):.4f}\")\n",
    "print(f\"Cohen's Kappa Score: {cohen_kappa_score(y_test, lgb_reduced_ypred):.4f}\")\n",
    "print(f\"Training Time: {lgb_train_minutes} minutes and {lgb_train_seconds:.2f} seconds\")\n",
    "print(f\"Inference Time: {lgb_infer_minutes} minutes and {lgb_infer_seconds:.2f} seconds\")"
   ],
   "id": "d6f1d7512cee4a24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[91211  8789]\n",
      " [ 5097 94903]]\n",
      "\n",
      "True Negatives (TN): 91211\n",
      "False Positives (FP): 8789\n",
      "False Negatives (FN): 5097\n",
      "True Positives (TP): 94903\n",
      "Accuracy: 0.9306\n",
      "AUC: 0.9833\n",
      "Precision: 0.9152\n",
      "Recall: 0.9490\n",
      "F1-Score: 0.9318\n",
      "Cohen's Kappa Score: 0.8611\n",
      "Training Time: 0 minutes and 6.33 seconds\n",
      "Inference Time: 0 minutes and 0.21 seconds\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Putting the Results into Perspective**",
   "id": "1ef22bec4fe5ec37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The accuracy is 1,99% worse than the accuracy of the DL model, which means 3980 less correctly labeled samples (4078 less true negatives, 4078 more false positives, 87 less false negatives, 87 more true positives)**",
   "id": "db6dea1113186bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**This LightGBM model was trained 217,31 times faster than the DL Model (6,33 seconds vs 22 minutes and 55,58 seconds)**",
   "id": "5f3359959354d39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The inference time for the 200,000 samples is 28,95 times faster than the DL Model (6,08 seconds vs. 0,21 seconds)**",
   "id": "1cf8c5814b652b20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**PART V: Training and Evaluating the Random Forest Model on the Full Dataset**",
   "id": "a6b2c664d76eb00a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T14:50:49.903518Z",
     "start_time": "2025-04-04T14:34:30.438811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rfm_full = RandomForestClassifier(n_estimators=100) #max_depth=None, min_samples_split=2\n",
    "rf_train_start = time.time()\n",
    "rfm_full.fit(X_train, y_train)\n",
    "rf_train_end = time.time()"
   ],
   "id": "ec67fff0f598b697",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T14:52:18.394796Z",
     "start_time": "2025-04-04T14:52:09.737075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Measure inference time\n",
    "rf_infer_start = time.time()\n",
    "rfm_full_ypred = rfm_full.predict(X_test)\n",
    "rf_infer_end = time.time()\n",
    "\n",
    "# Calculate inference time\n",
    "rf_inference_total_seconds = rf_infer_end - rf_infer_start\n",
    "rf_infer_minutes = int(rf_inference_total_seconds // 60)\n",
    "rf_infer_seconds = rf_inference_total_seconds % 60\n",
    "\n",
    "# Calculate training time\n",
    "rf_training_total_seconds = rf_train_end - rf_train_start\n",
    "rf_train_minutes = int(rf_training_total_seconds // 60)\n",
    "rf_train_seconds = rf_training_total_seconds % 60\n",
    "\n",
    "cm = confusion_matrix(y_test, rfm_full_ypred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rfm_full_ypred):.4f}\")\n",
    "rfmy_pred_proba = np.array(rfm_full.predict_proba(X_test))[:, 1]  # Probabilities for the positive class\n",
    "print(f\"AUC: {roc_auc_score(y_test, rfmy_pred_proba):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, rfm_full_ypred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, rfm_full_ypred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, rfm_full_ypred):.4f}\")\n",
    "print(f\"Cohen's Kappa Score: {cohen_kappa_score(y_test, rfm_full_ypred):.4f}\")\n",
    "print(f\"Training Time: {rf_train_minutes} minutes and {rf_train_seconds:.2f} seconds\")\n",
    "print(f\"Inference Time: {rf_infer_minutes} minutes and {rf_infer_seconds:.2f} seconds\")"
   ],
   "id": "2cf5661b2670e413",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[95854  4146]\n",
      " [ 5291 94709]]\n",
      "\n",
      "True Negatives (TN): 95854\n",
      "False Positives (FP): 4146\n",
      "False Negatives (FN): 5291\n",
      "True Positives (TP): 94709\n",
      "Accuracy: 0.9528\n",
      "AUC: 0.9899\n",
      "Precision: 0.9581\n",
      "Recall: 0.9471\n",
      "F1-Score: 0.9525\n",
      "Cohen's Kappa Score: 0.9056\n",
      "Training Time: 16 minutes and 19.46 seconds\n",
      "Inference Time: 0 minutes and 4.32 seconds\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Putting the Results into Perspective**",
   "id": "acb1fdbc3ddf715a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The accuracy is 1,62% worse than the accuracy of the RF model trained on the feature-reduced dataset, which means 3240 less correctly labeled samples (2027 less true negatives, 2027 more false positives, 1208 more false negatives, 1208 less true positives)**",
   "id": "69ef33b719365706"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Training an RF model on the feature-reduced dataset was 5,05 times faster (3 minutes and 13,83 seconds vs. 16 minutes and 19,46 seconds)**",
   "id": "aef34be6a044671f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The inference time for the 200,000 samples for the RF model trained on the feature-reduced dataset is 1,19 faster (3,64 seconds vs. 4,32 seconds)**",
   "id": "6620e126670ff760"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**PART VI: Training and Evaluating the LightGBM Model on the Full Dataset**",
   "id": "b6d8f9969385c239"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T16:19:10.774504Z",
     "start_time": "2025-04-05T16:18:52.351865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lgbm_full = lgb.LGBMClassifier() #boosting_type='gbdt; num_leaves=31: (Maximum number of leaves in one tree); max_depth=-1: (No limit on tree depth); learning_rate=0.1; n_estimators=100\n",
    "lgb_train_start = time.time()\n",
    "lgbm_full.fit(X_train, y_train)\n",
    "lgb_train_end = time.time()"
   ],
   "id": "6ee32e9095879ba8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 300000, number of negative: 300000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.081702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 213082\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 2339\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T16:19:32.245419Z",
     "start_time": "2025-04-05T16:19:31.787591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lgb_training_total_seconds = lgb_train_end - lgb_train_start\n",
    "lgb_train_minutes = int(lgb_training_total_seconds // 60)\n",
    "lgb_train_seconds = lgb_training_total_seconds % 60\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    lgb_infer_start = time.time()\n",
    "    lgb_full_ypred = lgbm_full.predict(X_test)\n",
    "    lgb_infer_end = time.time()\n",
    "    lgby_pred_proba = np.array(lgbm_full.predict_proba(X_test))[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "lgb_infer_total_seconds = lgb_infer_end - lgb_infer_start\n",
    "lgb_infer_minutes = int(lgb_infer_total_seconds // 60)\n",
    "lgb_infer_seconds = lgb_infer_total_seconds % 60\n",
    "\n",
    "cm = confusion_matrix(y_test, lgb_full_ypred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lgb_full_ypred):.4f}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, lgby_pred_proba):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, lgb_full_ypred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, lgb_full_ypred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, lgb_full_ypred):.4f}\")\n",
    "print(f\"Cohen's Kappa Score: {cohen_kappa_score(y_test, lgb_full_ypred):.4f}\")\n",
    "print(f\"Training Time: {lgb_train_minutes} minutes and {lgb_train_seconds:.2f} seconds\")\n",
    "print(f\"Inference Time: {lgb_infer_minutes} minutes and {lgb_infer_seconds:.2f} seconds\")"
   ],
   "id": "27c334c75b2a4781",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[92342  7658]\n",
      " [ 4490 95510]]\n",
      "\n",
      "True Negatives (TN): 92342\n",
      "False Positives (FP): 7658\n",
      "False Negatives (FN): 4490\n",
      "True Positives (TP): 95510\n",
      "Accuracy: 0.9393\n",
      "AUC: 0.9858\n",
      "Precision: 0.9258\n",
      "Recall: 0.9551\n",
      "F1-Score: 0.9402\n",
      "Cohen's Kappa Score: 0.8785\n",
      "Training Time: 0 minutes and 18.42 seconds\n",
      "Inference Time: 0 minutes and 0.18 seconds\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Putting the Results into Perspective**",
   "id": "d4a4ab8d0b22eaf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The accuracy is 0,87% better than the accuracy of the LightGBM model trained on the feature-reduced dataset (1131 false positives correctly reclassified as true negatives; 607 false negatives correctly reclassified as true positives).**",
   "id": "bf9c8d25d924f7e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**It underperforms both RF models (the one trained on the feature-reduced dataset as well as the one trained on the full dataset).**",
   "id": "ea74001f213d2a86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**It took 2,9 times more seconds to train this LightGBM model compared to the LightGBM model trained on the feature-reduced dataset (18,42 seconds vs. 6,33 seconds)**",
   "id": "eaf4395f9abf71ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The inference time is about the same (0,21 seconds for the LightGBM model trained on the feature-reduced dataset vs. 0,18 seconds for this model)**",
   "id": "e3ffb2ff6073f49d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
